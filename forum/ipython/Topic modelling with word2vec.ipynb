{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling with Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import [gensim library](https://radimrehurek.com/gensim/models/word2vec.html) to help us work with Word2vec. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import Phrases\n",
    "import ujson as json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice topic modelling requires a large quantity of training data to ensure good coverage. For this example though we trained the model on 10,000 posts so it runs nice and quick as a demo.\n",
    "\n",
    "*Unfortunately we cannot provide you with the data we used for this example. The data file we used contained line-delimited JSON, where each object had an content property, for example:*\n",
    "\n",
    "    { \"interaction\": { \"content\": \"Some example post content\" } }\n",
    "\n",
    "*You can easily adapt the sample() function below to yield words from sample data you have access to.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path='path to your data file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function yields individual words to be features in our model\n",
    "def sample():\n",
    "    with open(path) as f:\n",
    "        for idx,i in enumerate(f):\n",
    "            try:\n",
    "                j=json.loads(i)\n",
    "                doc=re.split('\\W+',j['interaction']['content'].lower())\n",
    "                yield doc\n",
    "            except Exception, e:\n",
    "                yield e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For example this is the first post broken into words\n",
    "for i in sample():\n",
    "    print i\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier, passing the sample() function as the source for the features:\n",
    "* **min_count** = number of times a word must appear in the training set to be included\n",
    "* **size** = the dimensionality of the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302070"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(min_count=10,size=300,workers=4)\n",
    "model.build_vocab(sample())\n",
    "model.train(sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3773"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of words/features in the model (plotted in the vector space)\n",
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01042447,  0.02375209, -0.01082089, -0.0425309 ,  0.08850687,\n",
       "        0.01835847,  0.09388897,  0.0229075 ,  0.06897521,  0.00579358,\n",
       "        0.02837576,  0.01110327,  0.04553978, -0.03796777, -0.03296932,\n",
       "       -0.0075057 ,  0.00058247,  0.00256892, -0.00880944, -0.03536413,\n",
       "        0.05947323,  0.07111327, -0.00194172, -0.04563519, -0.0275267 ,\n",
       "        0.05214039, -0.05474159,  0.01259535,  0.05187937, -0.04075418,\n",
       "        0.03328146, -0.13077228,  0.01483395,  0.0171774 ,  0.05006329,\n",
       "        0.09928679,  0.02557462,  0.02554442,  0.03180938,  0.10886257,\n",
       "        0.04842255,  0.01555276,  0.06251799,  0.08433534,  0.10723314,\n",
       "       -0.03573573,  0.00350808,  0.04262157, -0.01684722, -0.0122436 ,\n",
       "        0.02143183, -0.08224846, -0.10467756,  0.09027454,  0.04416394,\n",
       "        0.01605871,  0.07377852, -0.09633812, -0.03675043, -0.00154874,\n",
       "       -0.04733178,  0.10887686, -0.05309524,  0.0071005 ,  0.01628326,\n",
       "       -0.02001717, -0.01103722,  0.05804011, -0.00028361, -0.04290744,\n",
       "        0.02133279,  0.05465616,  0.06189318, -0.03590997,  0.05208958,\n",
       "       -0.09355932, -0.00759013,  0.00478174, -0.08406983,  0.04246479,\n",
       "       -0.13057552, -0.0441548 , -0.07660321, -0.08940677,  0.00432872,\n",
       "       -0.03041388,  0.04072847,  0.03471998,  0.06132725,  0.14342259,\n",
       "        0.00784987, -0.01239973,  0.03852315, -0.00927701, -0.0413664 ,\n",
       "       -0.04417321, -0.08303598, -0.11825824, -0.02952898, -0.07093406,\n",
       "        0.01698191,  0.00180032, -0.07226155,  0.00659927, -0.02283275,\n",
       "       -0.05113994, -0.03480766, -0.10039671, -0.03017891, -0.01937134,\n",
       "       -0.08531335,  0.01350268,  0.02937257,  0.08120131, -0.12045497,\n",
       "       -0.1246103 ,  0.04302335,  0.00345396,  0.13371791, -0.07007109,\n",
       "        0.01510312, -0.07530259, -0.0028548 ,  0.03431996,  0.02196657,\n",
       "       -0.10125869, -0.02872024,  0.11513165, -0.01810229,  0.02519207,\n",
       "        0.11074643, -0.01186762,  0.040334  , -0.06459327, -0.08090913,\n",
       "        0.08238314, -0.06170322, -0.02713988,  0.05985229,  0.04884371,\n",
       "       -0.03474706,  0.03818523,  0.01018515,  0.01721042,  0.10281587,\n",
       "        0.06035456, -0.10513461,  0.05733702,  0.01461475,  0.0607599 ,\n",
       "       -0.02546871, -0.05008281,  0.04072634,  0.04454647, -0.04577322,\n",
       "       -0.0128359 , -0.10048729, -0.00072664,  0.01221008, -0.12568772,\n",
       "        0.01009519,  0.05336345,  0.03654139, -0.02291409,  0.08154932,\n",
       "        0.01934095, -0.14029571, -0.00824031,  0.01112496,  0.07610753,\n",
       "        0.07847247,  0.07048249,  0.05128345, -0.04319774,  0.10608497,\n",
       "        0.03093352, -0.00344354, -0.02498775,  0.08965388,  0.09628556,\n",
       "        0.04703528, -0.14486076, -0.02790088,  0.04968257,  0.02398409,\n",
       "       -0.06733856,  0.08376309,  0.03283484,  0.02061984,  0.07481282,\n",
       "        0.06811316, -0.04459187,  0.02377148,  0.03741622, -0.01841045,\n",
       "       -0.05780716,  0.02640738,  0.07889636, -0.02419577, -0.02266623,\n",
       "        0.12225059,  0.00808691,  0.09550372, -0.00127386,  0.02283143,\n",
       "       -0.04343063, -0.0443139 , -0.03152174,  0.04045653, -0.0586701 ,\n",
       "       -0.01588358, -0.08568399, -0.0042373 , -0.00528397, -0.02200861,\n",
       "        0.0390897 ,  0.00488928,  0.05748381, -0.01752273, -0.01264135,\n",
       "       -0.07223334, -0.03703286,  0.01962196, -0.07682706,  0.08255947,\n",
       "       -0.03920481,  0.00728521, -0.05430747,  0.00267978,  0.00068749,\n",
       "        0.02188904,  0.11162292, -0.03886681, -0.02652116,  0.04522737,\n",
       "       -0.04902669,  0.03458332,  0.09082181,  0.04552715,  0.01169648,\n",
       "        0.00315526,  0.03401804, -0.01942235,  0.08847747,  0.0203769 ,\n",
       "        0.00287634,  0.06290794,  0.03242828, -0.00107381, -0.12422476,\n",
       "        0.08442481, -0.10874607, -0.09306954, -0.01038936,  0.04914089,\n",
       "        0.09353857, -0.04547897,  0.01421629,  0.01012502, -0.00166455,\n",
       "        0.04798993, -0.00275833,  0.03103978, -0.00188471, -0.00161534,\n",
       "       -0.02532945,  0.15236612, -0.10118474, -0.047975  ,  0.07854982,\n",
       "       -0.00315479, -0.00725539, -0.00180279, -0.07934686,  0.12801118,\n",
       "       -0.0789399 , -0.03028125,  0.00704698,  0.03427295, -0.01055583,\n",
       "        0.05262218,  0.03463443, -0.00697991,  0.01043445,  0.01053583,\n",
       "        0.0405135 ,  0.01722819, -0.00316036, -0.12431912,  0.06113207,\n",
       "       -0.04668739,  0.00743156, -0.14231397, -0.08170951,  0.054162  ,\n",
       "       -0.03086052,  0.08449575,  0.12100504, -0.09049913, -0.02599987], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words in the model are represented as a 300-dimension vector\n",
    "model['brake']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now query our simple model to look for term similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'pads', 0.8729451894760132),\n",
       " (u'discs', 0.8260030746459961),\n",
       " (u'coil', 0.8060240149497986),\n",
       " (u'battery', 0.8055069446563721),\n",
       " (u'clutch', 0.8049130439758301),\n",
       " (u'radiator', 0.8034414052963257),\n",
       " (u'alternator', 0.8013132810592651),\n",
       " (u'diff', 0.7878439426422119),\n",
       " (u'mounts', 0.7793276309967041),\n",
       " (u'plugs', 0.7779099345207214)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"brake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how terms collect around topics, for example the brand Ford relates most closely to terms from Ford models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'jeep', 0.7569979429244995),\n",
       " (u'subaru', 0.7534029483795166),\n",
       " (u'dodge', 0.7268344759941101),\n",
       " (u'xlt', 0.7241834402084351),\n",
       " (u'mustang', 0.7216092944145203),\n",
       " (u'05', 0.7102600336074829),\n",
       " (u'01', 0.7099963426589966),\n",
       " (u'lx', 0.7038288116455078),\n",
       " (u'2011', 0.6979385018348694),\n",
       " (u'f', 0.6966347694396973)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"ford\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would expect that brands would also have a strong level of similarity. In this case this is not immediately obvious and we may need a larger training set to train this into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'convertible', 0.8094639778137207),\n",
       " (u'subaru', 0.7635812759399414),\n",
       " (u'jeep', 0.7633465528488159),\n",
       " (u'01', 0.758976936340332),\n",
       " (u'17', 0.7423786520957947),\n",
       " (u'52', 0.7350496053695679),\n",
       " (u'volkswagen', 0.7329504489898682),\n",
       " (u'mustang', 0.7269424796104431),\n",
       " (u'lx', 0.7261062264442444),\n",
       " (u'suv', 0.72319495677948)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"ford\",\"audi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the model to identify terms that don't belong to a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wheel'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match([\"ford\", \"audi\", \"bmw\", \"wheel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that as our training set is small we quickly find terms that do not exist in the model. Topic modelling requires a large training set to make it effective for our use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'clio' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cafcc7939a95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"renault\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"clio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Python/2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot compute similarity with no input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'clio' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model.most_similar(positive=[\"renault\",\"clio\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Google News model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [word2vec project page](https://code.google.com/p/word2vec/) provides a sample dataset that you can download and load. The model is trained on content aggregated by Google News and contains 1 billion words.\n",
    "\n",
    "We can load this example model and explore the topic relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "google_news = Word2Vec.load_word2vec_format('/Users/richard/Downloads/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately we can see the similarity between topics such as countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Austria', 0.7461062073707581),\n",
       " (u'German', 0.7178748846054077),\n",
       " (u'Germans', 0.6628648042678833),\n",
       " (u'Switzerland', 0.6506868004798889),\n",
       " (u'Hungary', 0.6504981517791748),\n",
       " (u'Germnay', 0.649348258972168),\n",
       " (u'Netherlands', 0.6437495946884155),\n",
       " (u'Cologne', 0.6430778503417969),\n",
       " (u'symbol_RSTI', 0.6389946937561035),\n",
       " (u'Annita_Kirsten', 0.634294867515564)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news.most_similar(positive=['Germany'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And politicians..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Hillary_Clinton', 0.7631065845489502),\n",
       " (u'Obama', 0.7526832818984985),\n",
       " (u'Bill_Clinton', 0.7416832447052002),\n",
       " (u'Hillary_Rodham_Clinton', 0.7254317402839661),\n",
       " (u'Sen._Hillary_Clinton', 0.7086110711097717),\n",
       " (u'Hillary', 0.6970474720001221),\n",
       " (u'Senator_Hillary_Clinton', 0.6961780190467834),\n",
       " (u'McCain', 0.6851686835289001),\n",
       " (u'Clintons', 0.6733236312866211),\n",
       " (u'Barack_Obama', 0.6713167428970337)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news.most_similar(positive=['Clinton'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding multiple positive terms gives a stronger focus on a concept such as brands..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'BMW', 0.7375781536102295),\n",
       " (u'Porsche', 0.7340955138206482),\n",
       " (u'Volkswagen', 0.716567873954773),\n",
       " (u'Mercedes_Benz', 0.7152481079101562),\n",
       " (u'Nissan', 0.7118146419525146),\n",
       " (u'Volvo', 0.6946060657501221),\n",
       " (u'Mazda', 0.692476749420166),\n",
       " (u'Jaguar', 0.6696500182151794),\n",
       " (u'VW', 0.6689708232879639),\n",
       " (u'Toyota', 0.6618623733520508)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news.most_similar(positive=['Ford', 'Audi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also ask the model the similarity between any two terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62707561920002575"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news.similarity('Germany','France')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that China is considered less similar by the model, presumably because the stories and context in which it is discussed is different to Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38773252084548004"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news.similarity('Germany','China')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use vector maths to find related topics. \n",
    "\n",
    "For example here we're effectively asking for the capital of Germany. This works because the vector from France to Paris is approximately equal to the vector from Germany to Berlin in the vector space.\n",
    "\n",
    "    France - Paris ~= Germany - Capital of Germany\n",
    "\n",
    "Rearraning this...\n",
    "\n",
    "    Capital of Germany = Germany + Paris - France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'berlin', 0.4841364920139313),\n",
       " (u'german', 0.4656967520713806),\n",
       " (u'lindsay_lohan', 0.4559224843978882),\n",
       " (u'heidi', 0.44840937852859497),\n",
       " (u'switzerland', 0.44479838013648987),\n",
       " (u'lil_kim', 0.4430604577064514),\n",
       " (u'las_vegas', 0.4418063759803772),\n",
       " (u'christina', 0.43938425183296204),\n",
       " (u'joel', 0.4375365078449249),\n",
       " (u'russia', 0.43744248151779175)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news.most_similar(positive=['germany', 'paris'], negative=['france'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning to our example on banking. We can explore terms similar to 'bank'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'banks', 0.7440758943557739),\n",
       " (u'banking', 0.690161406993866),\n",
       " (u'Bank', 0.6698698401451111),\n",
       " (u'lender', 0.6342284679412842),\n",
       " (u'banker', 0.6092954277992249),\n",
       " (u'depositors', 0.6031532287597656),\n",
       " (u'mortgage_lender', 0.579797625541687),\n",
       " (u'depositor', 0.5716427564620972),\n",
       " (u'BofA', 0.5714625120162964),\n",
       " (u'Citibank', 0.5589520931243896)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news.most_similar(positive=['bank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again using multiple terms we can focus on well-known banks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'wells_fargo', 0.6432552337646484),\n",
       " (u'banks', 0.640464186668396),\n",
       " (u'citibank', 0.6323216557502747),\n",
       " (u'banking', 0.6259457468986511),\n",
       " (u'barclays', 0.6250307559967041),\n",
       " (u'citigroup', 0.6233223676681519),\n",
       " (u'BankAm', 0.6208717226982117),\n",
       " (u'Vietnam_Sacombank', 0.6041629314422607),\n",
       " (u'goldman_sachs', 0.599765956401825),\n",
       " (u'jpmorgan', 0.5980450510978699)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news.most_similar(positive=['bank','hsbc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
